# @package _global_

defaults:
  - /profiler: PytorchProfiler
  - /scheduler: linear_warmup_decay
  - override /strategy: null
  - override /datamodule: webdata_datamodule
  - override /loss: weighted_decoupled_contrastive_loss
  - override /datamodule/train_transforms: simclr_plankton
  - override /datamodule/valid_transforms: simclr_plankton
  - override /model/feature_extractor: simclr_resnet
  - override /model/classifier: simclr_v2_head
  - override /trainer: juwels
  - override /optimizer: lars
  - override /strategy: DDP
  - _self_

pretrain: true
debug: false
output_dir_base_path: /gpfs/work/machnitz/plankton_logs/pretrain
log_level: "INFO"
random_seed: 7

trainer:
  fast_dev_run: false
  num_sanity_val_steps: 5
  max_steps: 1000
  val_check_interval: 100
  limit_val_batches: 10
  accelerator: "gpu"
  plugins: null
  precision: 32
  num_nodes: 2
  devices: 2
  sync_batchnorm: true

logger:
  tensorboard:
    default_hp_metric: false

datamodule:
  num_workers: 10
  batch_size: 200
  oversample_data: false
  pin_memory: false
  reduce_data: false # use max 10.000 images from each class
  use_klas_data: true
  use_canadian_data: false
  use_planktonnet_data: false
  data_base_path: /gpfs/work/machnitz/plankton_dataset/webdataset/
  train_split: 0.997
  validation_split: 0.001

lightning_module:
  log_confusion_matrices: false
  log_images: false
  log_tsne_image: false
  temperature_scale: false

model:
  classifier:
    num_classes: 128 # size of the projection head
    input_features: 2048
  feature_extractor:
    model:
      _target_: "torchvision.models.resnet152"
      num_classes: ${model.classifier.input_features}
      pretrained: false
      # first conv layer:
    kernel_size: 7 # default is 7
    stride: 2 # default is 2
    channels: 3 # default is 3
    maxpool1: true

optimizer:
  lr: 4

loss:
  sync_ddp: true
