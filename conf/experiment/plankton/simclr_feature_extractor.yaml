# @package _global_

defaults:
  - callbacks/gpu_monitoring: gpu_monitoring
  - override /datamodule: plankton
  - override /datamodule/dataset: simclr
  - override /loss: nt_xent_loss
  - override /datamodule/train_transforms: simclr_plankton
  - override /datamodule/valid_transforms: simclr_plankton
  - override /model/feature_extractor: simclr_resnet
  - override /model/classifier: simclr_head
  - override /trainer: strand
  - override /hydra/launcher: strand
  - override /optimizer: lars
  - _self_

debug: false
scheduler: "linear_warmup_decay"

trainer:
  fast_dev_run: false
  num_sanity_val_steps: 5
  max_epochs: 800
  gpus: 2
  accelerator: ddp
  plugins: null
  precision: 16
  num_nodes: 2
  sync_batchnorm: true

hydra:
  launcher:
    partition: p2GPU32
    cpus_per_task: 20
    tasks_per_node: ${trainer.gpus} # == gpus_per_node
    nodes: ${trainer.num_nodes}

logger:
  tensorboard:
    default_hp_metric: false

datamodule:
  num_workers: 20
  batch_size: 128
  oversample_data: false
  pin_memory: false

lightning_module:
  log_confusion_matrices: false
  log_images: false

model:
  classifier:
    num_classes: 128  # size of the projection head
    input_features: 2048
  feature_extractor:
    model:
      _target_: "torchvision.models.resnet50"
#      _target_: "torchvision.models.resnet18"
      num_classes: ${model.classifier.input_features}
      pretrained: false
      # first conv layer:
    kernel_size: 7 # default is 7
    stride: 2 # default is 2
    channels: 3 # default is 3
    maxpool1: true

optimizer:
  lr: 2

callbacks:
  early_stopping:
    monitor: "loss/Validation"
    patience: 800
    verbose: true
    mode: "min"
