{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f681ab42-a578-4141-aa26-522db9f2db34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set()\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import hydra\n",
    "from src.lib.config import register_configs\n",
    "from src.models.LightningBaseModel import LightningModel\n",
    "from src.utils.CustomMetrics import MultiLabelAccuracy\n",
    "register_configs()\n",
    "try:\n",
    "    hydra.initialize(config_path=\"../conf\", job_name=\"plankton\")\n",
    "except ValueError:\n",
    "    print(ValueError)\n",
    "    \n",
    "import pytorch_lightning as pl\n",
    "from natsort import natsorted\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2addaef-7e5d-4b01-a0f5-2ca79d2bde92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Data splits:  [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n"
    }
   ],
   "source": [
    "# set global values:\n",
    "\n",
    "experiments_multilabel = {\n",
    "    \"supervised_multilabel\": \"/gpfs/work/machnitz/plankton_logs/supervised/multilabel/multirun/2022-04-19/08-13-41\",\n",
    "    \"linear_multilabel\": \"/gpfs/work/machnitz/plankton_logs/linear_eval/multilabel/multirun/2022-04-19/08-14-01\",\n",
    "    \"finetune_multilabel\": \"/gpfs/work/machnitz/plankton_logs/finetune/multilabel/multirun/2022-04-19/08-14-27\",\n",
    "    \"finetune_sgd_multilabel\": \"/gpfs/work/machnitz/plankton_logs/finetune_sgd/multilabel/multirun/2022-04-19/14-06-46\"\n",
    "}\n",
    "\n",
    "experiments_singlelabel = {\n",
    "    \"supervised_singlelabel\": \"/gpfs/work/machnitz/plankton_logs/supervised/singlelabel/multirun/2022-04-19/08-14-50\",\n",
    "    \"linear_singlelabel\": \"/gpfs/work/machnitz/plankton_logs/linear_eval/singlelabel/multirun/2022-04-19/19-15-20\",\n",
    "    \"finetune_singlelabel\": \"/gpfs/work/machnitz/plankton_logs/finetune/singlelabel/multirun/2022-04-19/08-15-24\",\n",
    "    \"finetune_sgd_singlelabel\": \"/gpfs/work/machnitz/plankton_logs/finetune_sgd/singlelabel/multirun/2022-04-19/08-15-10\"\n",
    "}\n",
    "\n",
    "data_splits_per_experiment = [np.round(x,2) for x in np.arange(0.01, 0.1, 0.01)] + [np.round(x, 2) for x in np.arange(0.1, 1.1, 0.1)]\n",
    "print(\"Data splits: \", data_splits_per_experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807252f0-2aac-4720-907a-8812503a8c99",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "hereon_color_array = np.array([\n",
    "    [230, 0, 70],\n",
    "    [0,145,160],\n",
    "    [0, 170, 230],\n",
    "    [250,180,35],\n",
    "    [0,70,125],\n",
    "    [175, 25, 60],\n",
    "    [170, 200 ,70],\n",
    "    [250,115,80],\n",
    "    [140, 90, 180],\n",
    "      \n",
    "])\n",
    "hereon_color_array = hereon_color_array / 255\n",
    "hereon_cmap = ListedColormap(hereon_color_array)\n",
    "\n",
    "sns.set_palette(hereon_color_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b05956-6c96-4465-86fd-c4335774cc6c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multi Label experiments\n",
    "\n",
    "We only need to load the config of the supervised run, since it only is used to init the data-loaders and they are the same for all single-label experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97ca0565-b47b-4a12-9598-828faceed77c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Global seed set to 7\n"
    }
   ],
   "source": [
    "pl.seed_everything(7)\n",
    "np.random.seed(7)\n",
    "cfg = hydra.compose(config_name=\"config\", overrides=[\"+experiment=plankton/publication/supervised_multilabel\", \n",
    "                                                     \"random_seed=7\", \n",
    "                                                     \"strategy=SingleDevice\", \n",
    "                                                     'strategy.device=\"cuda:0\"', \n",
    "                                                     \"trainer.enable_progress_bar=false\",\n",
    "                                                     \"datamodule.batch_size=200\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2221a9bc-0ae3-49ea-9a21-092d9a2c3bf5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/gpfs/home/machnitz/miniconda3/envs/plankton/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:95: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n  rank_zero_deprecation(\n"
    }
   ],
   "source": [
    "train_transforms = hydra.utils.instantiate(cfg.datamodule.train_transforms)\n",
    "valid_transforms = hydra.utils.instantiate(cfg.datamodule.valid_transforms)\n",
    "\n",
    "datamodule = hydra.utils.instantiate(\n",
    "    cfg.datamodule,\n",
    "    train_transforms=train_transforms,\n",
    "    valid_transforms=valid_transforms,\n",
    "    dataset=cfg.datamodule.dataset,\n",
    "    is_ddp=False,\n",
    ")\n",
    "datamodule.setup(stage=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4aaecac-5d10-42cf-b6b8-66cb34fcbe29",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "def get_confidence_and_acc(logits, labels, acc_func=MultiLabelAccuracy(weighted=True), n_bins=15):\n",
    "    ece = torch.zeros(1, device=logits.device)\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    softmaxes = F.softmax(logits, dim=1)\n",
    "    confidences, predictions = torch.max(softmaxes, 1)\n",
    "    accuracies = torch.tensor([acc_func(predictions=prediction.unsqueeze(0), \n",
    "                                            targets=label.unsqueeze(0), \n",
    "                                            n_labels=labels.max()+1) \n",
    "                               for prediction, label in zip(predictions, labels)])\n",
    "    accuracy_bins = []\n",
    "    confidence_bins = []\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated in each bin\n",
    "        in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        if prop_in_bin.item() > 0:\n",
    "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            accuracy_bins.append(accuracy_in_bin)\n",
    "            confidence_bins.append(avg_confidence_in_bin)\n",
    "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "    return torch.tensor(accuracy_bins), torch.tensor(confidence_bins), ece.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def instantiate_model(ckpt_path):\n",
    "    model = LightningModel.load_from_checkpoint(checkpoint_path=ckpt_path)\n",
    "    model.set_external_data(\n",
    "        class_labels=datamodule.unique_labels,\n",
    "        all_labels=datamodule.all_labels,\n",
    "        example_input_array=example_input.detach().cpu(),\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def instantiate_trainer():\n",
    "    trainer: Trainer = hydra.utils.instantiate(\n",
    "        cfg.trainer,\n",
    "        strategy=cfg.strategy,\n",
    "        logger=[],\n",
    "        callbacks=[],\n",
    "        _convert_=\"partial\",\n",
    "        profiler=None,\n",
    "    )\n",
    "    return trainer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "id": "abd35cf2"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1d1b23-48c4-4828-b121-24ec8be0e2a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m      2\u001B[0m trainer \u001B[38;5;241m=\u001B[39m instantiate_trainer()\n\u001B[1;32m      4\u001B[0m dataloader \u001B[38;5;241m=\u001B[39m datamodule\u001B[38;5;241m.\u001B[39mtest_dataloader()\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "assert False\n",
    "trainer = instantiate_trainer()\n",
    "\n",
    "dataloader = datamodule.test_dataloader()\n",
    "\n",
    "for batch in dataloader:\n",
    "    example_input, _ = batch\n",
    "    break\n",
    "    \n",
    "return_metrics = dict()\n",
    "for key, setup_path in experiments_multilabel.items():\n",
    "    experiment_folders = [os.path.join(setup_path, str(i)) for i in np.arange(0, 19)]\n",
    "    return_metrics[key] = dict()\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(20,15), sharex=True, sharey=True)\n",
    "    for experiment_number, experiment_path in enumerate(tqdm(experiment_folders)):\n",
    "        # print(experiment_number)\n",
    "        with open(os.path.join(experiment_path, \"main.log\"), \"r\") as f:\n",
    "            complete_log = f.readlines()\n",
    "            found_best_checkpoint = False\n",
    "            for line in complete_log:\n",
    "                # print(line)\n",
    "                if found_best_checkpoint:\n",
    "                    best_checkpoint = line.strip()\n",
    "                    # print(f\"set best checkpoint to {best_checkpoint}\")\n",
    "                    break\n",
    "                    \n",
    "                if \"[main.main][INFO] - Best checkpoint path:\" in line:\n",
    "                    found_best_checkpoint = True\n",
    "                    # print(f\"found best checkpoint: {line}\")\n",
    "            \n",
    "        model = instantiate_model(best_checkpoint)\n",
    "        return_metrics[key][experiment_number] = trainer.test(model, dataloader)[0]\n",
    "        return_metrics[key][experiment_number][\"Data Fraction\"] = data_splits_per_experiment[experiment_number]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                x, labels = batch\n",
    "                logits = model(x)[1]\n",
    "                \n",
    "                accuracies, confidences, ece = get_confidence_and_acc(logits, labels[1])\n",
    "                return_metrics[key][experiment_number][\"ECE\"] = ece\n",
    "        \n",
    "        ax = axes.flatten()[experiment_number]\n",
    "        sns.lineplot(x=confidences.cpu().numpy(), y=accuracies.cpu().numpy(), ax=ax)\n",
    "        ax.plot(np.linspace(0,1,100), np.linspace(0,1,100), c=\"grey\", ls=\"--\")\n",
    "        ax.set_xlabel(\"Confidence\")\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "        ax.set_title(f\"{key} | {data_splits_per_experiment[experiment_number]}\")\n",
    "        del model\n",
    "    plt.savefig(f\"ConfidenceAccuracy{key}.png\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f376343-684e-428d-87db-0a27ef275aa2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "reform = {(outerKey, innerKey): values for outerKey, innerDict in return_metrics.items() for innerKey, values in innerDict.items()}\n",
    "multi_label_df = pd.DataFrame.from_dict(reform).T\n",
    "multi_label_df.index.names = (\"Model\", \"Experiment\")\n",
    "multi_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755374dc-e711-4269-b619-4a91a636bc98",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "sns.lineplot(x=\"Data Fraction\", y=\"Accuracy/Testing\", hue=\"Model\", style=\"Model\", data=multi_label_df, ax=ax, palette=hereon_color_array,  markers=True, markersize=10,)\n",
    "\n",
    "for item in data_splits_per_experiment:\n",
    "    ax.text(item,0.3,f'{item * 100:.0f}%',color=\"grey\", horizontalalignment=\"center\", rotation=-45)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "plt.savefig(\"Accuracies_Testing_Multilabel.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aceb836-9afe-4f59-8b94-4dbba7bdc1fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "sns.lineplot(x=\"Data Fraction\", y=\"ECE\", hue=\"Model\", style=\"Model\", data=multi_label_df, ax=ax, palette=hereon_color_array,  markers=True, markersize=10,)\n",
    "\n",
    "for item in data_splits_per_experiment:\n",
    "    ax.text(item,0.2,f'{item * 100:.0f}%',color=\"grey\", horizontalalignment=\"center\", rotation=-45)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(loc=\"best\")\n",
    "plt.savefig(\"ECE_Testing_Multilabel.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9f4cf-c49f-4ae1-a5a5-ce35ef91ccee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "sns.lineplot(x=\"Data Fraction\", y=\"loss/Testing\", hue=\"Model\", style=\"Model\", data=multi_label_df, ax=ax, palette=hereon_color_array,  markers=True, markersize=10,)\n",
    "\n",
    "for item in data_splits_per_experiment:\n",
    "    ax.text(item,2,f'{item * 100:.0f}%',color=\"grey\", horizontalalignment=\"center\", rotation=-45)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(loc=\"best\")\n",
    "plt.savefig(\"KLDiv_Testing_Multilabel.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed179e-a1f9-455c-bf93-605e5058fd12",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Single Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8b403f-5539-4b41-a5ba-e9f20a84d1ec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Global seed set to 7\n"
    }
   ],
   "source": [
    "pl.seed_everything(7)\n",
    "np.random.seed(7)\n",
    "cfg = hydra.compose(config_name=\"config\", overrides=[\"+experiment=plankton/publication/supervised_singlelabel\", \n",
    "                                                     \"random_seed=7\", \n",
    "                                                     \"strategy=SingleDevice\", \n",
    "                                                     'strategy.device=\"cuda:0\"', \n",
    "                                                     \"trainer.enable_progress_bar=false\",\n",
    "                                                     \"datamodule.batch_size=200\",\n",
    "                                                     \"lightning_module.log_confusion_matrices=false\",\n",
    "                                                     \"lightning_module.temperature_scale=false\",\n",
    "                                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a28ad4a-4065-4853-ae0d-c9d80ed515c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/gpfs/home/machnitz/miniconda3/envs/plankton/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:95: LightningDeprecationWarning: DataModule property `train_transforms` was deprecated in v1.5 and will be removed in v1.7.\n  rank_zero_deprecation(\n77it [00:00, 4368.30it/s]                                                      | 0/19 [00:00<?, ?it/s]\n4536it [00:00, 7599.62it/s]\n88it [00:00, 3720.00it/s]█▎                                            | 2/19 [00:00<00:05,  3.23it/s]\n100it [00:00, 4362.16it/s]\n95it [00:00, 4930.45it/s]\n288it [00:00, 6502.45it/s]\n12it [00:00, 4121.15it/s]███████████▊                                  | 6/19 [00:00<00:01,  9.72it/s]\n158it [00:00, 7012.55it/s]\n59it [00:00, 6970.23it/s]\n1215it [00:00, 10737.09it/s]\n386it [00:00, 11836.02it/s]███████████████████▊                       | 10/19 [00:00<00:00, 14.30it/s]\n56it [00:00, 6301.98it/s]\n1290it [00:00, 11311.97it/s]\n207it [00:00, 6932.73it/s]████████████████████████████▌               | 13/19 [00:01<00:00, 15.53it/s]\n506it [00:00, 8265.73it/s]\n125299it [00:10, 11953.34it/s]\n4416it [00:00, 12848.97it/s]██████████████████████████████████▎       | 16/19 [00:11<00:03,  1.23s/it]\n1691it [00:00, 12557.53it/s]████████████████████████████████████▊     | 17/19 [00:11<00:02,  1.11s/it]\n2864it [00:00, 22216.26it/s]\nLoad Klas data: 100%|█████████████████████████████████████████████████| 19/19 [00:12<00:00,  1.55it/s]\n11it [00:00, 6910.93it/s]                                                      | 0/19 [00:00<?, ?it/s]\n648it [00:00, 12392.55it/s]\n12it [00:00, 5171.24it/s]\n14it [00:00, 5467.94it/s]\n13it [00:00, 5884.52it/s]\n41it [00:00, 4362.31it/s]\n1it [00:00, 1408.43it/s]\n22it [00:00, 8353.67it/s]\n8it [00:00, 6678.83it/s]\n173it [00:00, 14952.80it/s]\n55it [00:00, 19571.28it/s]████████████████████▊                       | 10/19 [00:00<00:00, 98.02it/s]\n8it [00:00, 7052.21it/s]\n184it [00:00, 17646.50it/s]\n29it [00:00, 10179.50it/s]\n72it [00:00, 10349.21it/s]\n17899it [00:01, 13466.76it/s]\n630it [00:00, 13211.40it/s]\n241it [00:00, 12578.42it/s]\n409it [00:00, 19977.53it/s]\nLoad Klas data: 100%|█████████████████████████████████████████████████| 19/19 [00:01<00:00, 12.21it/s]\n23it [00:00, 6905.44it/s]                                                      | 0/19 [00:00<?, ?it/s]\n1296it [00:00, 13476.04it/s]\n27it [00:00, 7216.81it/s]█▎                                            | 2/19 [00:00<00:00, 19.49it/s]\n29it [00:00, 9450.30it/s]\n29it [00:00, 7519.46it/s]\n83it [00:00, 6180.36it/s]\n5it [00:00, 5214.20it/s]\n46it [00:00, 9742.37it/s]\n18it [00:00, 8637.17it/s]\n348it [00:00, 15260.94it/s]\n111it [00:00, 17244.53it/s]\n16it [00:00, 8369.78it/s]\n370it [00:00, 17662.04it/s]\n61it [00:00, 8328.53it/s]█████████████████████████████▌               | 13/19 [00:00<00:00, 72.06it/s]\n145it [00:00, 9290.49it/s]\n35801it [00:02, 12006.41it/s]\n1263it [00:00, 11332.90it/s]\n484it [00:00, 11540.17it/s]\n819it [00:00, 21657.34it/s]\nLoad Klas data: 100%|█████████████████████████████████████████████████| 19/19 [00:03<00:00,  5.57it/s]\n"
    }
   ],
   "source": [
    "\n",
    "train_transforms = hydra.utils.instantiate(cfg.datamodule.train_transforms)\n",
    "valid_transforms = hydra.utils.instantiate(cfg.datamodule.valid_transforms)\n",
    "\n",
    "datamodule = hydra.utils.instantiate(\n",
    "    cfg.datamodule,\n",
    "    train_transforms=train_transforms,\n",
    "    valid_transforms=valid_transforms,\n",
    "    dataset=cfg.datamodule.dataset,\n",
    "    is_ddp=False,\n",
    ")\n",
    "datamodule.setup(stage=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ee2625c-2bb2-4610-a4e9-17e1e2d3b23e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "def get_confidence_and_acc_single(logits, labels, acc_func=None, n_bins=20, logits_are_probs=False):\n",
    "    ece = torch.zeros(1, device=logits.device)\n",
    "    bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    if not logits_are_probs:\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "    else:\n",
    "        softmaxes = logits\n",
    "    confidences, predictions = torch.max(softmaxes, 1)\n",
    "    accuracies = predictions.eq(labels)\n",
    "    accuracy_bins = []\n",
    "    confidence_bins = []\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        # Calculated in each bin\n",
    "        in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "        prop_in_bin = in_bin.float().mean()\n",
    "        if prop_in_bin.item() > 0:\n",
    "            accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "            avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "            accuracy_bins.append(accuracy_in_bin)\n",
    "            confidence_bins.append(avg_confidence_in_bin)\n",
    "            ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "    return torch.tensor(accuracy_bins), torch.tensor(confidence_bins), ece.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def run_and_save(_best_checkpoint, _dataloader, _return_metrics, _key, _experiment_number):\n",
    "    model = instantiate_model(_best_checkpoint)\n",
    "    model.log_confusion_matrices = False\n",
    "    model.temperature_scale = False\n",
    "    _return_metrics[_key][_experiment_number] = trainer.test(model, _dataloader)[0]\n",
    "    _return_metrics[_key][_experiment_number][\"Data Fraction\"] = data_splits_per_experiment[_experiment_number]\n",
    "    _logits = torch.empty(size=(len(_dataloader.dataset), len(datamodule.unique_labels))).to(\"cuda:0\")\n",
    "    _labels = torch.empty(size=[len(_dataloader.dataset)]).to(\"cuda:0\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        start = 0\n",
    "        for i, batch in tqdm(enumerate(_dataloader), total=(len(_dataloader))):\n",
    "            x, batch_labels = batch\n",
    "            end = start + len(batch_labels[0])\n",
    "            _labels[start: end] = batch_labels[0].squeeze()\n",
    "            _logits[start: end, :] = model(x)[1]\n",
    "\n",
    "            start = end\n",
    "\n",
    "    _labels = _labels.detach().cpu().int()\n",
    "    _logits = _logits.detach().cpu()\n",
    "\n",
    "    torch.save(_logits, f\"test_results/logits_{_key}_{_experiment_number}.pt\")\n",
    "    torch.save(_labels, f\"test_results/labels_{_key}_{_experiment_number}.pt\")\n",
    "    with open(f\"test_results/dict_{_key}_{_experiment_number}.pkl\", 'wb') as f:\n",
    "        pickle.dump(_return_metrics, f)\n",
    "    return _logits, _labels, _return_metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "id": "c5853c36"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def return_if_file_exists(func):\n",
    "    def function_wrapper(*args, **kwargs):\n",
    "        return func\n",
    "\n",
    "    file = function_wrapper()\n",
    "    if os.path.isfile:\n",
    "        return func\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"File {file} does not exist\")\n",
    "\n",
    "\n",
    "@return_if_file_exists\n",
    "def get_temperature_file(checkpoint_file):\n",
    "    if os.path.split(checkpoint_file)[-1] == \"last.ckpt\":\n",
    "        path = os.path.split(checkpoint_file)[0]\n",
    "        temp_files = natsorted(glob.glob(os.path.join(path, \"temperatures_*.tensor\")))\n",
    "        return temp_files[-1]\n",
    "    else:\n",
    "        return checkpoint_file.replace(\"epoch=\", \"temperatures_\").replace(\".ckpt\", \".tensor\")\n",
    "\n",
    "@return_if_file_exists\n",
    "def get_distribution_file(checkpoint_file):\n",
    "    path = os.path.split(checkpoint_file)[0]\n",
    "    return os.path.join(path, \"training_label_distribution.pt\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "id": "b00252c6"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1ea867d-2e4f-48c9-a877-66623921cd3e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "GPU available: True, used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n`Trainer(limit_train_batches=1.0)` was configured so 100% of the batches per epoch will be used..\n`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\n`Trainer(limit_test_batches=1.0)` was configured so 100% of the batches will be used..\n"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd65d4c7195d4749ab98c611f0f74939"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n/gpfs/home/machnitz/miniconda3/envs/plankton/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 200. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  warning_cache.warn(\n/gpfs/home/machnitz/miniconda3/envs/plankton/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 174. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n  warning_cache.warn(\n"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1m       Test metric       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      DataLoader 0       \u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│\u001B[36m \u001B[0m\u001B[36m    Accuracy/Testing     \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m  0.012813003733754158   \u001B[0m\u001B[35m \u001B[0m│\n│\u001B[36m \u001B[0m\u001B[36m      loss/Testing       \u001B[0m\u001B[36m \u001B[0m│\u001B[35m \u001B[0m\u001B[35m    36.21129608154297    \u001B[0m\u001B[35m \u001B[0m│\n└───────────────────────────┴───────────────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│<span style=\"color: #008080; text-decoration-color: #008080\">     Accuracy/Testing      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.012813003733754158    </span>│\n│<span style=\"color: #008080; text-decoration-color: #008080\">       loss/Testing        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     36.21129608154297     </span>│\n└───────────────────────────┴───────────────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/205 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e22b892eda34d09b3f0bddfeb55e835"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'logits' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 10>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     34\u001B[0m         return_metrics \u001B[38;5;241m=\u001B[39m pickle\u001B[38;5;241m.\u001B[39mload(f)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 36\u001B[0m     logits, labels, return_metrics \u001B[38;5;241m=\u001B[39m \u001B[43mrun_and_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_checkpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_metrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexperiment_number\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     38\u001B[0m accuracies, confidences, ece \u001B[38;5;241m=\u001B[39m get_confidence_and_acc_single(logits, labels, acc_func\u001B[38;5;241m=\u001B[39macc_func)\n\u001B[1;32m     39\u001B[0m return_metrics[key][experiment_number][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mECE\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m ece\n",
      "Input \u001B[0;32mIn [12]\u001B[0m, in \u001B[0;36mrun_and_save\u001B[0;34m(_best_checkpoint, _dataloader, _return_metrics, _key, _experiment_number)\u001B[0m\n\u001B[1;32m     14\u001B[0m         end \u001B[38;5;241m=\u001B[39m start \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch_labels[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     15\u001B[0m         labels[start: end] \u001B[38;5;241m=\u001B[39m batch_labels[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msqueeze()\n\u001B[0;32m---> 16\u001B[0m         \u001B[43mlogits\u001B[49m[start: end, :] \u001B[38;5;241m=\u001B[39m model(x)[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     18\u001B[0m         start \u001B[38;5;241m=\u001B[39m end\n\u001B[1;32m     20\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mint()\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m: local variable 'logits' referenced before assignment"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1440x1080 with 20 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = instantiate_trainer()\n",
    "    \n",
    "test_dataloader = datamodule.test_dataloader()\n",
    "for example_input, _ in test_dataloader:\n",
    "    break\n",
    "\n",
    "acc_func = torchmetrics.Accuracy(average=\"none\", num_classes=len(datamodule.unique_labels))\n",
    "    \n",
    "return_metrics = dict()\n",
    "for key, setup_path in experiments_singlelabel.items():\n",
    "    experiment_folders = [os.path.join(setup_path, str(i)) for i in np.arange(0, 19)]\n",
    "    return_metrics[key] = dict()\n",
    "    fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(20,15), sharex=True, sharey=True)\n",
    "    for experiment_number, experiment_path in enumerate(tqdm(experiment_folders)):\n",
    "        print(experiment_number)\n",
    "        with open(os.path.join(experiment_path, \"main.log\"), \"r\") as f:\n",
    "            complete_log = f.readlines()\n",
    "            found_best_checkpoint = False\n",
    "            for line in complete_log:\n",
    "                # print(line)\n",
    "                if found_best_checkpoint:\n",
    "                    best_checkpoint = line.strip()\n",
    "                    # print(f\"set best checkpoint to {best_checkpoint}\")\n",
    "                    break\n",
    "                    \n",
    "                if \"[main.main][INFO] - Best checkpoint path:\" in line:\n",
    "                    found_best_checkpoint = True\n",
    "                    # print(f\"found best checkpoint: {line}\")\n",
    "        if os.path.isfile(f\"test_results/labels_{key}_{experiment_number}.pt\"):\n",
    "            print(f\"loading {key}_{experiment_number} from file\")\n",
    "            logits = torch.load(f\"test_results/logits_{key}_{experiment_number}.pt\")\n",
    "            labels = torch.load(f\"test_results/labels_{key}_{experiment_number}.pt\")\n",
    "            with open(f\"test_results/dict_{key}_{experiment_number}.pkl\", 'rb') as f:\n",
    "                return_metrics = pickle.load(f)\n",
    "        else:\n",
    "            logits, labels, return_metrics = run_and_save(best_checkpoint, test_dataloader, return_metrics, key, experiment_number)\n",
    "\n",
    "        accuracies, confidences, ece = get_confidence_and_acc_single(logits, labels, acc_func=acc_func)\n",
    "        return_metrics[key][experiment_number][\"ECE\"] = ece\n",
    "\n",
    "        prob_scaling = EvalWrapper(temperature_file=get_temperature_file(best_checkpoint),\n",
    "                                   training_distribution_file=get_distribution_file(best_checkpoint),\n",
    "                                   device=\"cpu\")\n",
    "\n",
    "        corrected_probabilities = prob_scaling(logits=logits, correct_probabilities_with_training_prior=True)\n",
    "        accuracies_corrected, confidences_corrected, ece_corrected = get_confidence_and_acc_single(corrected_probabilities,\n",
    "                                                                                                   labels,\n",
    "                                                                                                   acc_func=acc_func,\n",
    "                                                                                                   logits_are_probs=True)\n",
    "        temp_scaled_logits = prob_scaling(logits=logits, correct_probabilities_with_temperature=True)\n",
    "        accuracies_temp, confidences_temp, ece_temp = get_confidence_and_acc_single(temp_scaled_logits,\n",
    "                                                                                    labels,\n",
    "                                                                                    acc_func=acc_func,\n",
    "                                                                                    logits_are_probs=False)\n",
    "        temp_and_prior_corrected_probabilities = prob_scaling(logits=temp_scaled_logits,\n",
    "                                                              correct_probabilities_with_training_prior=True)\n",
    "        accuracies_temp_and_corrected, confidences_temp_and_corrected, ece_temp_and_corrected = get_confidence_and_acc_single(temp_and_prior_corrected_probabilities, labels, acc_func=acc_func, logits_are_probs=False)\n",
    "\n",
    "        ax = axes.flatten()[experiment_number]\n",
    "        sns.lineplot(x=confidences.cpu().numpy(), y=accuracies.cpu().numpy(), ax=ax, label=\"pure NN outputs\")\n",
    "        sns.lineplot(x=confidences_corrected.cpu().numpy(), y=accuracies_corrected.cpu().numpy(), ax=ax, label=\"prior corrected outputs\")\n",
    "        sns.lineplot(x=confidences_temp.cpu().numpy(), y=accuracies_temp.cpu().numpy(), ax=ax, label=\"temp scaled outputs\")\n",
    "        sns.lineplot(x=confidences_temp_and_corrected.cpu().numpy(), y=accuracies_temp_and_corrected.cpu().numpy(), ax=ax, label=\"temp scaled and corrected\")\n",
    "        ax.plot(np.linspace(0,1,100), np.linspace(0,1,100), c=\"grey\", ls=\"--\")\n",
    "        ax.set_xlabel(\"Confidence\")\n",
    "        ax.set_ylabel(\"Accuracy\")\n",
    "        ax.set_title(f\"{key} | {data_splits_per_experiment[experiment_number]}\")\n",
    "        ax.legend(loc=\"best\")\n",
    "    plt.savefig(f\"ConfidenceAccuracy{key}.png\", dpi=300)\n",
    "    plt.show()\n",
    "    plt.close(\"all\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a4d81-1c52-4f7e-a44d-4d5421580862",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "\n",
    "datamodule.setup(stage=\"fit\")\n",
    "val_dataloader = datamodule.val_dataloader()\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    example_input, _ = batch\n",
    "    break\n",
    "\n",
    "val_logits, val_labels, val_return_metrics = run_and_save(best_checkpoint, val_dataloader, return_metrics, key+\"valid\", experiment_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad187524-eb32-4e4f-b364-0e4230e614e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "\n",
    "datamodule.setup(stage=\"test\")\n",
    "test_dataloader = datamodule.test_dataloader()\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    example_input, _ = batch\n",
    "    break\n",
    "\n",
    "test_logits, test_labels, test_return_metrics = run_and_save(best_checkpoint, test_dataloader, return_metrics, key+\"test_new\", experiment_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950fc000-d522-4627-8db8-5548cf83b5a7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "reform = {(outerKey, innerKey): values for outerKey, innerDict in return_metrics.items() for innerKey, values in innerDict.items()}\n",
    "single_label_df = pd.DataFrame.from_dict(reform).T\n",
    "single_label_df.index.names = (\"Model\", \"Experiment\")\n",
    "single_label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9ef2a-3f79-424e-b26c-2389cfb2f9da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "sns.lineplot(x=\"Data Fraction\", y=\"Accuracy/Testing\", hue=\"Model\", style=\"Model\", data=single_label_df, ax=ax, palette=hereon_color_array,  markers=True, markersize=10,)\n",
    "\n",
    "# for item in data_splits_per_experiment:\n",
    "#     ax.text(item,0.3,f'{item * 100:.0f}%',color=\"grey\", horizontalalignment=\"center\", rotation=-45)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "plt.savefig(\"Accuracies_Testing_Singlelabel.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecba306-d534-4c4b-910b-80e41e9f7910",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "sns.lineplot(x=\"Data Fraction\", y=\"ECE\", hue=\"Model\", style=\"Model\", data=single_label_df, ax=ax, palette=hereon_color_array,  markers=True, markersize=10,)\n",
    "\n",
    "for item in data_splits_per_experiment:\n",
    "    ax.text(item,0.2,f'{item * 100:.0f}%',color=\"grey\", horizontalalignment=\"center\", rotation=-45)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(loc=\"best\")\n",
    "plt.savefig(\"ECE_Testing_Singlelabel.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5920f7-58f6-4cb8-85a6-aa242a406def",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "sns.lineplot(x=\"Data Fraction\", y=\"loss/Testing\", hue=\"Model\", style=\"Model\", data=single_label_df, ax=ax, palette=hereon_color_array,  markers=True, markersize=10,)\n",
    "\n",
    "for item in data_splits_per_experiment:\n",
    "    ax.text(item,2,f'{item * 100:.0f}%',color=\"grey\", horizontalalignment=\"center\", rotation=-45)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(loc=\"best\")\n",
    "plt.savefig(\"NLL_Testing_Singlelabel.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701413fd-84bc-4b34-886f-6ea63de73181",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Plankton",
   "language": "python",
   "name": "plankton"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}